---
layout: single
title: "LLM 추론의 기초"
date: 2025-11-04 22:30:00 +0900
categories: ai
tags: [llm, ai]
excerpt: "LLM 추론에서 텍스트 생성 과정과 성능 지표에 대해 알아보겠습니다."
---

### LLM 텍스트 생성 프로세스
LLM은 2단계 프로세스로 텍스트를 생성합니다.

1. Prefill (질의 의미 파악)

- 입력 프롬프트를 토큰화하고 해당 토큰들을 병렬로 처리
- 사용자의 질의 의도를 파악하는 단계

2. Decoding (모델 답변 생성)

- 자동 회귀 방식으로 한 번에 하나의 토큰을 생성하여 텍스트 생성
- 생성된 각 토큰은 이전에 주어진 컨텍스트에 추가되고 모델에 다시 피드백하여 다음 토큰 생성
- LLM이 현재 토큰을 생성한 다음 사용자 입력과 중간 토큰을 종합하여 최종 토큰 생성 여부를 결정

→ 이때 텍스트를 토큰화하는 규칙은 모델마다 차이가 있으므로 토큰 기반 메트릭(e.g. 초당 토큰 수)은 성능의 좋은 기준이 될 수 없습니다.

### LLM 성능의 중요 지표

추론 속도에 대해서는 아래 4가지 지표가 사용됩니다.

1. 첫 번째 토큰까지의 시간 (TTFT, Time to First Token)

- 사용자가 쿼리를 입력한 후 모델의 결과물을 얼마나 빨리 볼 수 있는지 측정

2. 출력 토큰당 시간 (TPOT, Time Per Output Token)

- 각 사용자에 대해 출력 토큰을 생성하는 데 걸리는 시간

3. 지연 시간 (Latency)

- 모델이 사용자에 대한 전체 응답을 생성하는 데 걸리는 총 시간
- 지연 시간 = TTFT + TPOT * 생성할 토큰 수

4. 처리량 (Throughput)

- 주로 서버가 모든 사용자의 요청에 대해 생성할 수 있는 초당 출력 토큰의 수

목표: 가장 빠른 TTFT, TPOT와 가장 높은 Throughput → 최대한 많은 사용자를 위해 가능한 한 빠르게 텍스트를 생성하는 모델

### 처리량과 출력 토큰당 시간 사이의 Tradeoff

16개의 사용자 쿼리를 동시에 처리하면 처리량은 높아지지만 TPOT는 더 오래 걸립니다.

### LLM 계산에서 고려할 사항

1. 모델 파라미터를 GPU 메모리에서 로컬 캐시/레지스터(GPU의)로 얼마나 빨리 로드할 수 있는지
2. 로드된 데이터를 얼마나 빨리 계산할 수 있는지

→ GPU 연산 유닛에서의 계산은 매우 빠르나 GPU가 메모리에서 레지스터로 가중치를 로드할 때 메모리 대역폭에서 병목이 걸립니다. 이를 위해 아래와 같은 추론 최적화 기술이 개발되었습니다:

- 양자화(Quantization): 파라미터 크기를 줄여 메모리 대역폭 감소
- KV 캐싱: 중복 계산 방지
- 가중치 프루닝: 불필요한 파라미터를 제거해 메모리 전송량 감소